---
layout: default
---
<title>Russell Tsuchida</title>
<meta name="description" content="Personal webpage of Russell Tsuchida, postdoctoral resarch fellow in machine learning.">

<div class="jumbotron text-center">
    <div class="container"> 
     <p style = "float: left;"> <img src="static/photo.jpg" height="257px" width="213px" /></p>
    <p>
    <h2>Russell Tsuchida</h2>
    Postdoctoral Research Fellow (Machine Learning) <br/> 
    <a href="https://research.csiro.au/mlai-fsp/" target="_blank">MLAI Future Science Platform</a>, Data61 <br />
    CSIRO, Canberra, Australia </br>
    Email: russell.tsuchida_at_data61.csiro.au</p>
    </div>
</div>


<div class ="container">    
    <li class="auto-style5"><strong>Earlier:</strong>
        <p> PhD student in the <a href="http://www.itee.uq.edu.au/" target="_blank">School of ITEE</a> at the <a href="https://www.uq.edu.au/" target="_blank">University of Queensland</a> advised by <a href="http://staff.itee.uq.edu.au/marcusg/" target="_blank">Assoc. Prof. Marcus Gallagher</a> and <a href="https://people.smp.uq.edu.au/FredRoosta/" target="_blank">Fred Roosta</a>.</p> 
    </li>
</div>

<br>
<hr>

<div class ="container">
    <h3>News</h3> 
        <li class="auto-style5"><strong>May, 2022:</strong> <p> I am a <a href="https://iclr.cc/Conferences/2022/Reviewers" target="_blank">ICLR 2022 Highlighted reviewer!</a> I also had a great time attending the conference.</p>
    </li>    
                    <li class="auto-style5"><strong>January, 2022:</strong> <p> Our paper about a connection between Deep Equilibrium models and Deep Declarative networks has been accepted into ICLR 2022! You can read the submission and reviews <a href="https://openreview.net/forum?id=q4HaTeMO--y" target="_blank">here.</a> </p>
    </li>     
    
                <li class="auto-style5"><strong>December, 2021:</strong> <p><a href="https://arxiv.org/abs/2112.13029" target="_blank">Gaussian Process Bandits with Aggregated Feedback</a> has been accepted into AAAI 2022 (with a controversially low acceptance rate of 15%).</p>
    </li>     
    
                <li class="auto-style5"><strong>October, 2021:</strong> <p> We submitted a paper to ICLR 2022.</p>
    </li>        
    
            <li class="auto-style5"><strong>October, 2021:</strong> <p> Honoured to recieve a <a href="https://nips.cc/Conferences/2021/ProgramCommittee" target="_blank">NeurIPS 2021 Outstanding Reviewer Award</a>!</p>
    </li>        
    
            <li class="auto-style5"><strong>August, 2021:</strong> <p> I thoroughly enjoyed working with Mengyan Zhang and Cheng Soon Ong on <a href="https://arxiv.org/abs/2112.13029" target="_blank">Gaussian Process Bandits with Aggregated Feedback</a>.</p>
    </li>
    
     <!--<li class="auto-style5"><strong>December, 2020:</strong> <p> My doctorate has been conferred! </p>
    </li>    -->  
    
     <!--<li class="auto-style5"><strong>December, 2020:</strong> <p> <a href="https://arxiv.org/abs/2002.08517" target="_blank">Avoiding Kernel Fixed Points: Computing with ELU and GELU Infinite Networks</a> has been accepted into AAAI 2021! </p>
    </li> -->
    
     <!--<li class="auto-style5"><strong>February, 2020:</strong> <p> Very pleased to share our new work, <a href="https://arxiv.org/abs/2002.08517" target="_blank">Avoiding Kernel Fixed Points: Computing with ELU and GELU Infinite Networks</a>.</p>
    </li> -->
    
     <!--<li class="auto-style5"><strong>November, 2019:</strong> <p> We have a new paper on arXiv, <a href="https://arxiv.org/abs/1911.12927" target="_blank">Richer priors for infinitely wide multi-layer perceptrons</a>.</p>
    </li> -->
    
    <!--<li class="auto-style5"><strong>May, 2019:</strong> <p> I am the co-author of a paper from a successful collaboration with <a href="https://github.com/TeaPearce" target="_blank"> Tim Pearce</a>,  <a href="https://arxiv.org/pdf/1905.06076.pdf" target="_blank"> Expressive Priors in Bayesian Neural Networks: Kernel Combinations and Periodic Functions</a>, which has been accepted into UAI 2019.</p>-->
    
    <!--<li class="auto-style5"><strong>May, 2019:</strong> <p> Our paper <a href="https://arxiv.org/abs/1810.08351" target="_blank">Exchangeability and Kernel Invariance in Trained MLPs</a> has been accepted into IJCAI 2019.</p>
    </li> -->
    
    <!--<li class="auto-style5"><strong>October, 2018:</strong> <p> We have a new paper on arXiv, <a href="https://arxiv.org/abs/1810.08351" target="_blank">Exchangeability and Kernel Invariance in Trained MLPs</a>.</p>
    </li> -->
    
    <!--<li class="auto-style5"><strong>May, 2018:</strong> <p> Our workshop "Rotationally Invariant Weights, the Central Limit Theorem, and Geometry of Activations in MLPs" has been accepted by <a href="http://gimli.cc/2018/" target="_blank">GiMLi 2018!</a> and I have been awarded a travel award for ICML 2018!</p>
    </li> -->

    <!--<li class="auto-style5"><strong>May, 2018:</strong> <p> Our paper "Invariance of Weight Distributions in Rectified MLPs" has been accepted into ICML 2018!</p>
    </li> -->

    <!-- <li class="auto-style5"><strong>Nov, 2017:</strong> <p> Posted a <a href="https://arxiv.org/abs/1711.09090" target="_blank">paper</a>  on the arXiv discussing invariance of neural networks with respect to weight distributions, including how the Central Limit Theorem applies to the equivalent kernel of neural networks.</p>
    </li> -->

</div>


<hr>


<div class ="container">
    <h3>Selected publications</h3>
        <li class="auto-style5"><strong>2022:</strong> <p>   <strong> Russell Tsuchida, </strong>, Suk Yee Yong, Ali Armin, Lars Petersson,  Cheng Soon Ong. <a href="https://openreview.net/forum?id=q4HaTeMO--y" target="_blank">Declarative nets that are equilibrium models.</a> ICLR 2022. </p> </li> 
        
    
        <li class="auto-style5"><strong>2022:</strong> <p>  Mengyan Zhang, <strong> Russell Tsuchida, </strong> Cheng Soon Ong. <a href="https://arxiv.org/abs/2112.13029" target="_blank">Gaussian Process Bandits with Aggregated Feedback.</a> AAAI 2022.</p> </li> 
        
    <li class="auto-style5"><strong>2021:</strong> <p> <strong>  Russell Tsuchida, </strong> Tim Pearce, Christopher van der Heide, Fred Roosta and Marcus Gallagher. <a href="https://arxiv.org/abs/2002.08517" target="_blank">Avoiding Kernel Fixed Points: Computing with ELU and GELU Infinite Networks.</a> AAAI 2021.</p> </li> 
    
    <li class="auto-style5"><strong>2019:</strong> <p> <strong>  Russell Tsuchida, </strong> Fred Roosta and Marcus Gallagher. <a href="https://arxiv.org/abs/1911.12927" target="_blank">Richer priors for infinitely wide multi-layer perceptrons.</a> Pre-print.</p> </li> 
   
    
    <li class="auto-style5"><strong>2019:</strong> <p> Tim Pearce, <strong> Russell Tsuchida, </strong> Mohamed Zaki, Alexandra Brintrup and Andy Neely. 
Expressive Priors in Bayesian Neural Networks: Kernel Combinations and Periodic Functions. In Conference on Uncertainty in Artificial Intelligence, 2019.</p>
    </li>
    <li class="auto-style5"><strong>2019:</strong> <p> <strong> Russell Tsuchida</strong>, Fred Roosta, and Marcus Gallagher. 
Exchangeability and Kernel Invariance in Trained MLPs. In International Joint Conference on Artificial Intelligence, 2019.</p>
    </li>
    <li class="auto-style5"><strong>2018:</strong> <p> <strong> Russell Tsuchida</strong>, Fred Roosta, and Marcus Gallagher. <a href="http://proceedings.mlr.press/v80/tsuchida18a.html" target="_blank">Invariance of Weight Distributions in Rectified MLPs.</a> In International Conference on Machine Learning, pp. 5002-5011, 2018.</p>
    </li>
</div>


<hr>


<div class ="container">
    <h3>Students</h3>
        <li class="auto-style5">   <a href="https://mengyanz.github.io/" target="_blank">Mengyan Zhang.</a> (ANU), co-advised with <a href="http://www.ong-home.my/" target="_blank">Cheng Soon Ong,</a> 2020- </li> 
        
       <li class="auto-style5">  Changkun Ye (ANU), co-advised with <a href="http://users.cecs.anu.edu.au/~nmb/" target="_blank">Nick Barnes</a> and <a href="https://people.csiro.au/P/L/Lars-Petersson" target="_blank">Lars Petersson</a>, 2020- </li> 
</div>


<hr>
